<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Examples on CoMLRL</title><link>/docs/examples/</link><description>Recent content in Examples on CoMLRL</description><generator>Hugo</generator><language>en-us</language><atom:link href="/docs/examples/index.xml" rel="self" type="application/rss+xml"/><item><title>CoMLRL Quick Demo</title><link>/docs/examples/quick-demo/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/docs/examples/quick-demo/</guid><description>&lt;p&gt;This tutorial demonstrates how to train two LLM agents to collaborate to tell a story. The first agent generates a compact story setup, while the second agent produces a longer version. The reward function encourages the second agent&amp;rsquo;s output to be 2–3× longer than the first agent&amp;rsquo;s.&lt;/p&gt;
&lt;p&gt;To run this demo, please have at least 24 GB of GPU memory available. You can also visualize the training process by setting up your WandB dashboard.&lt;/p&gt;</description></item></channel></rss>